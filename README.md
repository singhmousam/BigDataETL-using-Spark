# BigDataETL-using-Spark
Learning to ETL a large csv data file to JSON format and exploring and storing it in document database using SparkSQL as ETL tool and HDFS as storage.

Large health payment dataset, JSON, Apache Spark, and HDFS are an interesting combination for a health analytics workshop because:

JSON is an open-standard and efficient format that uses human-readable text to represent, transmit, and interpret data objects consisting of attribute-value pairs. Because JSON is easy for computer languages to manipulate, JSON has supplanted XML for web and mobile applications.
Newer standards for exchanging healthcare information such as FHIR are easier to implement because they use a modern web-based suite of API technology, including REST and JSON.
Apache Spark SQL, DataFrames, and datasets make it easy to load, process, transform, and analyze JSON data.

You can download the dataset from here-https://www.cms.gov/openpayments/.

You have to change input and output data directory path. If you want to use HDFS instead of local file system then replace the path accordingly after starting your hdfs.

*******singhmousam4@gmail.com********
